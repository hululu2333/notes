### 独立部署模式

***

> 独立部署表示资源管理任务调度框架和计算框架都用spark自己的
>
> spark的独立调度器分为master和worker。master相当于是ResourceManager，worker相当于是NodeManager



#### 配置

> 修改slaves文件，添加worker节点

``` bash
mv slaves.template slaves
vi slaves

#加入以下内容
hadoop01
hadoop02
hadoop03
```

***

> 修改spark-env.sh文件，指定master位置

``` bash
SPARK_MASTER_HOST=hadoop01
SPARK_MASTER_PORT=7077
```

***

> 分发这些配置文件

``` bash
xsync spark/conf/
```



#### 启动

``` bash
#启动master和worker服务
spark/sbin/start-all.sh
```

> 如果显示没有找到JAVA_HOME，就修改spark-config.sh。加入以下配置

``` bash
export JAVA_HOME=/opt/module/jdk
```



#### 运行案例

``` bash
bin/spark-submit --class org.apache.spark.examples.SparkPi \
--executor-memory 1G \
--master spark://hadoop01:7077 \
--total-executor-cores 2 \
./examples/jars/spark-examples_2.11-2.1.1.jar 100
```

 

