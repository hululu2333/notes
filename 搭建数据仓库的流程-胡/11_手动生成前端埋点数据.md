### 手动生成前端埋点数据——日志文件

***

#### 上传jar包

> 将之前在IDEA上写的用来生成埋点数据的jar包上传到hadoop01和hadoop02。
>
> hadoop03上不要这个，因为hadoop03上的Flume用来消费数据
>
> 三台服务器上各有一个Flume，hadoop01和hadoop02上的用来传输数据，hadoop03上的用来消费



#### 运行生成数据的主程序

> 利用java命令来运行jar包有两种方式。
> 一是java -jar test.jar。这种方法只接收一个参数。主类的全类名的这个参数由系统从MANIFEST.MF文件中的MainClass这个属性获得。当我们的jar包里只有一个主类时，MainClass的值就是这个主类的全类名。如果有多个jar包，则不会有MainClass这个属性
>
> 当我们的jar包里有多个主类，我们需要指定主类的全类名才能运行我们想运行的那个主类。这时我们只能用java -classpath test.jar Test

```bash
#将运行程序时的日志信息存入test.log中
#我们需要的埋点数据在/tmp/logs文件夹中
java -classpath generate_log-1.0-SNAPSHOT-jar-with-dependencies.jar com.hu.appclient.AppMain > /opt/module/test.log

#如果我们想让这些输出不保存在文件里，也不打印在控制台上，我们可以这样
java -classpath generate_log-1.0-SNAPSHOT-jar-with-dependencies.jar com.hu.appclient.AppMain 1>/dev/null 2>/dev/null
#1是标准输出，默认目的地是控制台。我们把目的地改为linux黑洞——/dev/null。任何进入黑洞的数据都不会被保存。2是错误输出，将其目的地也改为黑洞
```

  

#### 编写一键生成数据的脚本

```bash
#!/bin/bash

for i in hadoop01 hadoop02
do
	ssh $i "java -classpath /opt/modulegenerate_log-1.0-SNAPSHOT-jar-with-dependencies.jar com.hu.appclient.AppMain 1>/dev/null 2>/dev/null"
	echo $i 日志生成成功
done
```



#### 修改埋点数据的时间

> 我们手动生成埋点数据，埋点数据的时间就是生成他的时间。但我们需要不同时间的埋点数据，所以我们生成数据之前要改变当前的系统时间

```bash
#将当前日期修改为2020年5月23日
sudo data -s 2020-5-23
```



#### 编写一键修改集群时间的脚本

```bash
#!/bin/bash

for i in hadoop01 hadoop02 hadoop03
do
	#当你远程连接其他主机，又想使用sudo时，需要加-t命令
	#加-t后会生成一个虚拟终端
	ssh -t $i "sudo date -s $1"
done
```



#### 编写一键执行命令的脚本

```bash
#!/bin/bash

for i in hadoop01 hadoop02 hadoop03
do
	#$*的意思是命令后的所有参数都放在这里
	ssh $i "$*"
done
```

